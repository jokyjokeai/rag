# RAG Local System - Intelligent Knowledge Base

[![GitHub](https://img.shields.io/badge/github-jokyjokeai%2Frag-blue?logo=github)](https://github.com/jokyjokeai/rag)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)
[![Status](https://img.shields.io/badge/status-95%25%20complete-success)](documentation/PROJECT_STATUS.md)

Syst√®me RAG (Retrieval-Augmented Generation) local et intelligent pour l'ingestion, le traitement et l'interrogation de contenus techniques multi-sources.

üéâ **Version 1.0 - Production Ready** | [Documentation compl√®te](documentation/) | [GitHub Repo](https://github.com/jokyjokeai/rag)

## üéØ Caract√©ristiques

- **100% Local & Open Source** (sauf Brave Search API - 2000 req/mois gratuit)
- **D√©tection automatique** : URLs vs prompts texte
- **Multi-sources** : YouTube (cha√Ænes/vid√©os), GitHub (repos), Sites web (documentation)
- **Chunking intelligent** adapt√© au type de contenu
- **Enrichissement m√©tadonn√©es** via Ollama (LLM local)
- **Pas de doublons** : Syst√®me de hash pour √©viter les duplicatas
- **Queue syst√®me** : Traitement par batch avec priorisation
- **Refresh automatique** : Maintien √† jour hebdomadaire
- **Interface MCP** : Compatible Claude Code et chat custom

## üêõ Corrections r√©centes (v1.0)

### Bugs critiques corrig√©s
- **Quota tracking** : Correction du format datetime (SQLite compatibility)
- **Seuil de recherche** : Ajustement du threshold de 0.3 √† 1.5 pour plus de r√©sultats
- **Requ√™tes concurrentes** : Ajout d'un flag optionnel `ENABLE_COMPETITOR_QUERIES`

### Am√©liorations
- Meilleure documentation avec .env.example
- Structure de projet organis√©e (dossier documentation/)
- Suppression de tous les scripts de test temporaires
- Configuration Git compl√®te (.gitignore)

## üèóÔ∏è Architecture

```
Input (URLs ou Prompt)
    ‚Üì
Orchestrator (d√©tection + Ollama + Brave Search)
    ‚Üì
URL Discovery Layer (SQLite - pas de doublons)
    ‚Üì
Queue Manager (priorisation + batch)
    ‚Üì
Scrapers (YouTube, GitHub, Web)
    ‚Üì
Processing (chunking + embeddings + enrichissement)
    ‚Üì
Vector Database (ChromaDB)
    ‚Üì
MCP Server (search_rag, add_source, get_status)
```

## üöÄ Installation

### Pr√©requis

- Python 3.11+
- Ollama install√© et en cours d'ex√©cution
- Cl√©s API (optionnelles) : Brave Search, YouTube, GitHub

### Installation

```bash
# 1. Clone et navigation
cd rag-local-system

# 2. Environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. D√©pendances
pip install -r requirements.txt

# 4. Playwright (pour sites web dynamiques)
playwright install

# 5. Configuration
cp .env.example .env
# √âditer .env avec vos cl√©s API

# 6. Ollama
ollama pull llama3.2
```

## ‚öôÔ∏è Configuration (.env)

```bash
# APIs (optionnelles mais recommand√©es)
BRAVE_API_KEY=votre_cle_brave
YOUTUBE_API_KEY=votre_cle_youtube
GITHUB_TOKEN=votre_token_github

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Chemins
CHROMA_DB_PATH=./data/chroma_db
SQLITE_DB_PATH=./data/discovered_urls.db

# Processing
BATCH_SIZE=10
CONCURRENT_WORKERS=3
MAX_CHUNK_SIZE=512
```

## üìñ Utilisation

### Mode URL direct

```python
from orchestrator import Orchestrator

orch = Orchestrator()

# Ajouter des URLs directement
result = orch.process_input("""
https://fastapi.tiangolo.com
https://github.com/tiangolo/fastapi
https://www.youtube.com/@ArjanCodes
""")

print(f"‚úÖ {result['urls_added']} URLs ajout√©es")
```

### Mode Prompt (recherche web)

```python
from orchestrator import Orchestrator

orch = Orchestrator()

# Prompt textuel - Ollama analyse + Brave Search
result = orch.process_input("Je veux apprendre FastAPI avec PostgreSQL")

print(f"üîç {result['urls_discovered']} URLs d√©couvertes")
print(f"‚úÖ {result['urls_added']} URLs ajout√©es")
```

## üîß Composants

### 1. Orchestrator
- D√©tecte type d'entr√©e (URL vs prompt)
- Analyse prompts avec Ollama
- Recherche web via Brave Search API
- Ajoute URLs √† la base de donn√©es

### 2. Database Layer
- **SQLite** : `discovered_urls` avec d√©tection doublons
- **ChromaDB** : Stockage vectoriel des chunks

### 3. Crawlers (√† venir)
- YouTube : D√©couverte vid√©os depuis cha√Ænes
- GitHub : Listing fichiers repos
- Web : Crawl r√©cursif avec limite profondeur

### 4. Scrapers (√† venir)
- YouTube : Transcriptions via `youtube-transcript-api`
- GitHub : Code + docs via PyGithub
- Web : HTML ‚Üí Markdown

### 5. Processing Pipeline (√† venir)
- Chunking intelligent par type
- Embeddings locaux (`sentence-transformers`)
- Enrichissement m√©tadonn√©es (Ollama)

### 6. MCP Server (√† venir)
- `search_rag` : Recherche s√©mantique
- `add_source` : Ajout URLs
- `get_source_status` : Stats syst√®me

## üìä Statut du projet

‚úÖ **Production Ready (95% compl√©t√©)**

**Composants op√©rationnels :**
- ‚úÖ Orchestrator (d√©tection URL/prompt, Brave Search, Ollama)
- ‚úÖ Database layer (SQLite + ChromaDB)
- ‚úÖ Scrapers (YouTube, GitHub, Web) avec crawlers
- ‚úÖ Processing pipeline (chunking, embeddings, enrichissement)
- ‚úÖ Queue manager (batch async processing)
- ‚úÖ MCP server (Claude Desktop integration)
- ‚úÖ CLI interface (10 commandes interactives)
- ‚úÖ Auto-refresh scheduler
- ‚úÖ Rate limiting & quota tracking

**D√©tails du projet :**
- 13,164 lignes de code Python
- 432 chunks dans ChromaDB
- 18 fichiers de documentation
- Architecture modulaire et extensible

## üìù Exemple complet

```python
# Initialisation
from orchestrator import Orchestrator

orch = Orchestrator()

# Cas 1: URLs directes
orch.process_input("https://fastapi.tiangolo.com")

# Cas 2: Prompt textuel
orch.process_input("Apprendre FastAPI async")

# Statistiques
stats = orch.get_stats()
print(stats)

# Fermeture
orch.close()
```

## üîí Respect & √âthique

- ‚úÖ Respect `robots.txt`
- ‚úÖ Rate limiting (1 req/sec par domaine)
- ‚úÖ User-Agent identifiable
- ‚úÖ Retry avec backoff exponentiel
- ‚úÖ Respect des limites API

## üìö Stack technique

- **LLM** : Ollama (llama3.2)
- **Vector DB** : ChromaDB
- **Database** : SQLite
- **Embeddings** : sentence-transformers
- **Web scraping** : Playwright, BeautifulSoup
- **YouTube** : youtube-transcript-api
- **GitHub** : PyGithub
- **Processing** : LangChain, tiktoken

## ü§ù Contribution

Contributions bienvenues ! Le projet suit une architecture modulaire et extensible.

### Comment contribuer

1. Fork le projet
2. Cr√©ez une branche pour votre feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

### Guidelines

- Code Python conforme √† PEP 8
- Documentation en fran√ßais ou anglais
- Tests pour les nouvelles fonctionnalit√©s
- Logs structur√©s avec loguru

## üìÑ Licence

MIT License - voir fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üôè Remerciements

- [Ollama](https://ollama.ai/) pour l'inf√©rence LLM locale
- [ChromaDB](https://www.trychroma.com/) pour la base vectorielle
- [Brave Search](https://brave.com/search/api/) pour l'API de recherche web
- Communaut√© open source pour les biblioth√®ques utilis√©es

---

**Projet d√©velopp√© avec Claude Code** | [Documentation](documentation/) | [Issues](https://github.com/jokyjokeai/rag/issues)
